"""
å¿«é€Ÿæµ‹è¯•ï¼šéªŒè¯ TransformerEncoder ç»´åº¦ä¿®å¤

è¿è¡Œæ­¤è„šæœ¬ä»¥éªŒè¯ä¿®å¤æ˜¯å¦æˆåŠŸ
"""

import torch
from model_xlearner import TransformerEncoder

print("="*60)
print("æµ‹è¯• TransformerEncoder ç»´åº¦ä¿®å¤")
print("="*60)

# æµ‹è¯•ä¸åŒçš„èŠ‚ç‚¹æ•°ï¼ˆåŒ…æ‹¬ä¸èƒ½è¢«4æ•´é™¤çš„ï¼‰
test_cases = [
    100,   # ä¸èƒ½è¢«4æ•´é™¤
    200,   # èƒ½è¢«4æ•´é™¤
    268,   # ABCD å¯èƒ½çš„èŠ‚ç‚¹æ•°
    300,   # ä¸èƒ½è¢«4æ•´é™¤
]

success_count = 0
failed_count = 0

for num_nodes in test_cases:
    print(f"\næµ‹è¯• num_nodes={num_nodes}:")
    
    try:
        # åˆ›å»ºç¼–ç å™¨
        encoder = TransformerEncoder(
            input_dim=num_nodes,
            d_model=128,  # èƒ½è¢« 4 æ•´é™¤
            nhead=4,
            num_layers=2
        )
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 2
        x = torch.randn(batch_size, num_nodes, num_nodes)
        out = encoder(x)
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        expected_shape = (batch_size, num_nodes, 128)
        assert out.shape == expected_shape, f"å½¢çŠ¶ä¸åŒ¹é…: {out.shape} vs {expected_shape}"
        
        print(f"  âœ“ æˆåŠŸ! è¾“å…¥: [{batch_size}, {num_nodes}, {num_nodes}]")
        print(f"  âœ“ è¾“å‡º: {out.shape}")
        success_count += 1
        
    except AssertionError as e:
        print(f"  âœ— å¤±è´¥: {e}")
        failed_count += 1
    except Exception as e:
        print(f"  âœ— é”™è¯¯: {type(e).__name__}: {e}")
        failed_count += 1

print("\n" + "="*60)
print("æµ‹è¯•æ€»ç»“")
print("="*60)
print(f"æ€»è®¡: {len(test_cases)} ä¸ªæµ‹è¯•")
print(f"æˆåŠŸ: {success_count} âœ“")
print(f"å¤±è´¥: {failed_count} âœ—")

if failed_count == 0:
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼TransformerEncoder ä¿®å¤æˆåŠŸï¼")
else:
    print(f"\nâš ï¸  {failed_count} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")

print("="*60)

